{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# IPython candies...\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, tensor, autograd\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "feb13fc88688cd77d0f4266f0d95f6b5e341bfa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12d93a2f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(12, 8)})\n",
    "\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "b6e71245b5e82a99ce01f914e6efc37e5dd771b0"
   },
   "outputs": [],
   "source": [
    "try: # Use the default NLTK tokenizer.\n",
    "    from nltk import word_tokenize, sent_tokenize \n",
    "    # Testing whether it works. \n",
    "    # Sometimes it doesn't work on some machines because of setup issues.\n",
    "    word_tokenize(sent_tokenize(\"This is a foobar sentence. Yes it is.\")[0])\n",
    "except: # Use a naive sentence tokenizer and toktok.\n",
    "    import re\n",
    "    from nltk.tokenize import ToktokTokenizer\n",
    "    # See https://stackoverflow.com/a/25736515/610569\n",
    "    sent_tokenize = lambda x: re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', x)\n",
    "    # Use the toktok tokenizer that requires no dependencies.\n",
    "    toktok = ToktokTokenizer()\n",
    "    word_tokenize = word_tokenize = toktok.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "e66bf66fae3734f95241eebc5ac8d11e61718bfe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import io #codecs\n",
    "\n",
    "\n",
    "# Text version of https://kilgarriff.co.uk/Publications/2005-K-lineer.pdf\n",
    "if os.path.isfile('language-never-random.txt'):\n",
    "    with io.open('language-never-random.txt', encoding='utf8') as fin:\n",
    "        text = fin.read()\n",
    "else:\n",
    "    url = \"https://gist.githubusercontent.com/alvations/53b01e4076573fea47c6057120bb017a/raw/b01ff96a5f76848450e648f35da6497ca9454e4a/language-never-random.txt\"\n",
    "    text = requests.get(url).content.decode('utf8')\n",
    "    with io.open('language-never-random.txt', 'w', encoding='utf8') as fout:\n",
    "        fout.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "10e3d0a9d7d39774d41e60326ecf82f939dedcf6"
   },
   "outputs": [],
   "source": [
    "# Tokenize the text.\n",
    "tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
    "                  for sent in sent_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "d971921fc3975505d0db84eca326744fb98c1ced"
   },
   "outputs": [],
   "source": [
    "class KilgariffDataset(nn.Module):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "        \n",
    "        # Initialize the vocab \n",
    "        special_tokens = {'<pad>': 0, '<unk>':1, '<s>':2, '</s>':3}\n",
    "        self.vocab = ???\n",
    "        self.vocab.patch_with_special_tokens(special_tokens)\n",
    "        \n",
    "        # Keep track of the vocab size.\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        \n",
    "        # Keep track of how many data points.\n",
    "        self._len = ???\n",
    "        \n",
    "        # Find the longest text in the data.\n",
    "        self.max_len = max(len(txt) for txt in texts) \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        vectorized_sent = self.vectorize(self.texts[index])\n",
    "        x_len = len(vectorized_sent)\n",
    "        # To pad the sentence:\n",
    "        # Pad left = 0; Pad right = max_len - len of sent.\n",
    "        pad_dim = (0, self.max_len - len(vectorized_sent))\n",
    "        vectorized_sent = F.pad(vectorized_sent, pad_dim, 'constant')\n",
    "        return {'x':vectorized_sent[???], \n",
    "                'y':vectorized_sent[???], \n",
    "                'x_len':x_len}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def vectorize(self, tokens, start_idx=2, end_idx=3):\n",
    "        \"\"\"\n",
    "        :param tokens: Tokens that should be vectorized. \n",
    "        :type tokens: list(str)\n",
    "        \"\"\"\n",
    "        # See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx \n",
    "        # Lets just cast list of indices into torch tensors directly =)\n",
    "        \n",
    "        vectorized_sent = [start_idx] + self.vocab.???(tokens) + [end_idx]\n",
    "        return torch.tensor(vectorized_sent)\n",
    "    \n",
    "    def unvectorize(self, indices):\n",
    "        \"\"\"\n",
    "        :param indices: Converts the indices back to tokens.\n",
    "        :type tokens: list(int)\n",
    "        \"\"\"\n",
    "        return [self.vocab[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "4e39ea3edc9855cbc71e0b4e8c18dd1ca84e827f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1392"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kilgariff_data = KilgariffDataset(tokenized_text)\n",
    "len(kilgariff_data.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "149f189249edf73258f9456e86c2116cc2da3150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[   2,  184,  248,  ...,    0,    0,    0],\n",
      "        [   2,  344,  327,  ...,    0,    0,    0],\n",
      "        [   2,  269,   52,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2,  994, 1388,  ...,    0,    0,    0],\n",
      "        [   2,  747,  799,  ...,    0,    0,    0],\n",
      "        [   2, 1206, 1389,  ...,    0,    0,    0]]), 'y': tensor([[ 184,  248,   73,  ...,    0,    0,    0],\n",
      "        [ 344,  327,  392,  ...,    0,    0,    0],\n",
      "        [ 269,   52,   35,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 994, 1388, 1272,  ...,    0,    0,    0],\n",
      "        [ 747,  799,  123,  ...,    0,    0,    0],\n",
      "        [1206, 1389,    3,  ...,    0,    0,    0]]), 'x_len': tensor([40, 31, 27, 19, 18, 17, 16, 16, 14,  4])}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "dataloader = DataLoader(dataset=kilgariff_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data_dict in dataloader:\n",
    "    # Sort indices of data in batch by lengths.\n",
    "    sorted_indices = np.array(data_dict['x_len']).argsort()[::-1].tolist()\n",
    "    data_batch = {name:_tensor[sorted_indices]\n",
    "                  for name, _tensor in data_dict.items()}\n",
    "    print(data_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "5aa5c2bd3bd13d6870441dec284d7762d6b8f1bd"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, num_layers):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of input (i.e. no. of words in input vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.???(???, ???, padding_idx=0)\n",
    "        \n",
    "        # Initialize the GRU with the \n",
    "        # - size of the input (i.e. embedding layer)\n",
    "        # - size of the hidden layer \n",
    "        self.gru = nn.GRU(???, ???, num_layers, batch_first=True)\n",
    "        \n",
    "        # Initialize the \"classifier\" layer to map the RNN outputs\n",
    "        # to the vocabulary. Remember we need to -1 because the \n",
    "        # vectorized sentence we left out one token for both x and y:\n",
    "        # - size of hidden_size of the GRU output.\n",
    "        # - size of vocabulary\n",
    "        self.classifier = nn.???(???, ???)\n",
    "        \n",
    "    def forward(self, inputs, use_softmax=False, hidden=None):\n",
    "        # Look up for the embeddings for the input word indices.\n",
    "        embedded = self.???(inputs)\n",
    "        # Put the embedded inputs into the GRU.\n",
    "        output, hidden = self.???(embedded, hidden)\n",
    "        \n",
    "        # Matrix manipulation magic.\n",
    "        batch_size, sequence_len, hidden_size = output.shape\n",
    "        # Technically, linear layer takes a 2-D matrix as input, so more manipulation...\n",
    "        output = output.contiguous().view(batch_size * sequence_len, hidden_size)\n",
    "        # Apply dropout.\n",
    "        output = F.???(output, 0.5)\n",
    "        # Put it through the classifier\n",
    "        # And reshape it to [batch_size x sequence_len x vocab_size]\n",
    "        output = self.classifier(output).view(batch_size, sequence_len, -1)\n",
    "        \n",
    "        return (F.softmax(output,dim=2), hidden) if use_softmax else (output, hidden)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "dce2418b4cede1f5dd3f104179fa69defaeceac3"
   },
   "outputs": [],
   "source": [
    "# Set the hidden_size of the GRU \n",
    "embed_size = 12\n",
    "hidden_size = 10\n",
    "num_layers = 1\n",
    "\n",
    "_encoder = Generator(len(kilgariff_data.vocab), embed_size, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "0d24dcec5ce293c82663ecf9ce07528d1f125882"
   },
   "outputs": [],
   "source": [
    "# Take a batch.\n",
    "batch_size = 15\n",
    "dataloader = DataLoader(dataset=kilgariff_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "_batch = next(iter(dataloader))\n",
    "_inputs, _lengths = _batch['x'], _batch['x_len']\n",
    "_targets = _batch['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "009c1cc8d9f7517187bd9259473703baf5cbd349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output sizes:\t torch.Size([15, 183, 1392])\n",
      "Input sizes:\t 15 183 1392\n",
      "Target sizes:\t torch.Size([15, 183])\n"
     ]
    }
   ],
   "source": [
    "_output, _hidden = _encoder(_inputs)\n",
    "print('Output sizes:\\t', _output.shape)\n",
    "print('Input sizes:\\t', batch_size, kilgariff_data.max_len -1, len(kilgariff_data.vocab))\n",
    "print('Target sizes:\\t', _targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "b5ddd1dfa0736a64152d1b3acbedb118606d4a38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 183, 1392])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "ee773d9ff037f57b0ba49a0594f5ffb546da3498"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([183, 1392])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_output[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "07a81647f4724bc89e31eb0aaca301839d23b9fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 1392])\n"
     ]
    }
   ],
   "source": [
    "_, predicted_indices = torch.max(_output, dim=1)\n",
    "print(predicted_indices.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "cc11b8af72aa329ceb43d3b9e40d96efea23cb84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hyperparams(embed_size=250, hidden_size=250, num_layers=1, loss_func=<class 'torch.nn.modules.loss.CrossEntropyLoss'>, learning_rate=0.03, optimizer=<class 'torch.optim.adam.Adam'>, batch_size=245)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "_hyper = ['embed_size', 'hidden_size', 'num_layers',\n",
    "          'loss_func', 'learning_rate', 'optimizer', 'batch_size']\n",
    "Hyperparams = namedtuple('Hyperparams', _hyper)\n",
    "\n",
    "\n",
    "hyperparams = Hyperparams(embed_size=250, hidden_size=250, num_layers=1,\n",
    "                          loss_func=nn.CrossEntropyLoss,\n",
    "                          learning_rate=0.03, optimizer=optim.Adam, batch_size=245)\n",
    "\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "2654e746605c6480d1cc4cc1cf8b6c59fa3eefa4"
   },
   "outputs": [],
   "source": [
    "# Training routine.\n",
    "def train(num_epochs, dataloader, model, criterion, optimizer):\n",
    "    losses = []\n",
    "    plt.ion()\n",
    "    for _e in range(num_epochs):\n",
    "        for batch in tqdm(dataloader):\n",
    "            # Zero gradient.\n",
    "            optimizer.zero_grad()\n",
    "            x = batch['x'].to(???)\n",
    "            x_len = batch['x_len'].to(???)\n",
    "            y = batch['y'].to(???)\n",
    "            # Feed forward. \n",
    "            output, hidden = ???(x, use_softmax=False)\n",
    "            # Compute loss:\n",
    "            # Shape of the `output` is [batch_size x sequence_len x vocab_size]\n",
    "            # Shape of `y` is [batch_size x sequence_len]\n",
    "            # CrossEntropyLoss expects `output` to be [batch_size x vocab_size x sequence_len]\n",
    "            _, prediction = torch.???(output, dim=2)\n",
    "            loss = ???(output.permute(0, 2, 1), y)\n",
    "            loss.???()\n",
    "            optimizer.???()\n",
    "            losses.append(loss.float().data)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.plot(losses)\n",
    "        plt.pause(0.05)\n",
    "\n",
    "\n",
    "def initialize_data_model_optim_loss(hyperparams):\n",
    "    # Initialize the dataset and dataloader.\n",
    "    kilgariff_data = KilgariffDataset(tokenized_text)\n",
    "    dataloader = DataLoader(dataset=kilgariff_data, \n",
    "                            batch_size=hyperparams.batch_size, \n",
    "                            shuffle=True)\n",
    "\n",
    "    # Loss function.\n",
    "    criterion = hyperparams.loss_func(ignore_index=kilgariff_data.vocab.token2id['<pad>'], \n",
    "                                      reduction='mean')\n",
    "\n",
    "    # Model.\n",
    "    model = Generator(len(kilgariff_data.vocab), hyperparams.embed_size, \n",
    "                      hyperparams.hidden_size, hyperparams.num_layers).to(device)\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = hyperparams.optimizer(model.parameters(), lr=hyperparams.learning_rate)\n",
    "    \n",
    "    return dataloader, model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "5a5b3b2c17ba23fbb976f4a634ddd21e80e26c91"
   },
   "outputs": [],
   "source": [
    "def generate_example(model, temperature=1.0, max_len=100, hidden_state=None):\n",
    "    start_token, start_idx = '<s>', 2\n",
    "    # Start state.\n",
    "    inputs = torch.tensor(kilgariff_data.vocab.token2id[start_token]).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    sentence = [start_token]\n",
    "    i = 0\n",
    "    while i < max_len and sentence[-1] not in ['</s>', '<pad>']:\n",
    "        i += 1\n",
    "        \n",
    "        embedded = model.embedding(inputs)\n",
    "        output, hidden_state = model.gru(embedded, hidden_state)\n",
    "\n",
    "        batch_size, sequence_len, hidden_size = output.shape\n",
    "        output = output.contiguous().view(batch_size * sequence_len, hidden_size)    \n",
    "        output = model.classifier(output).view(batch_size, sequence_len, -1).squeeze(0)\n",
    "        #_, prediction = torch.max(F.softmax(output, dim=2), dim=2)\n",
    "        \n",
    "        word_weights = output.div(temperature).exp().cpu()\n",
    "        if len(word_weights.shape) > 1:\n",
    "            word_weights = word_weights[-1] # Pick the last word.    \n",
    "        word_idx = torch.multinomial(word_weights, 1).view(-1)\n",
    "        \n",
    "        sentence.append(kilgariff_data.vocab[int(word_idx)])\n",
    "        \n",
    "        inputs = tensor([kilgariff_data.vocab.token2id[word] for word in sentence]).unsqueeze(0).to(device)\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "de7efc9371e23d8ec2c73d647fdfc06a2805a573"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD7CAYAAABpJS8eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU1f3/8ddMNrKzBRL2/cMWiCDUHVu3ggtCRaxQ3JUK/qxLbbWb+m211arfWtRWLWrFulXAyiJ1+7pURUVWwYMaiOyEiGRhC4TfHzPYECGZJJPcWd7Px4MHzDn3Zj6fx+HxmZtz5tzrO3DgACIiEvv8XgcgIiLNQwVfRCROqOCLiMQJFXwRkTihgi8iEicSvQ7gCFKAYcAmYL/HsYiIRIsEIA/4ENhTszNSC/4w4G2vgxARiVInAu/UbIzUgr8JYPv2Cqqq6r9PoE2bDEpKysMelBeUS2SKlVxiJQ9QLgB+v49WrdIhWENritSCvx+gqupAgwr+wXNjhXKJTLGSS6zkAcqlmsNOhWvRVkQkTqjgi4jECRV8EZE4oYIvIhInVPBFROJEnd/SMbPLganVmroDTzrnplY7ZjRwG+AD1gCXOOe2m9kk4A/AluChc51zvwhX8CIiEro6r/Cdc4865wqccwXABGArcOvBfjPLAh4CznTODQaWVesfBlx/8PzmKPYbtlVw2e9eoXBjaVO/lYhIVKnvlM5DwC3OuW3V2pKAq51zG4KvlwFdgv8eBkwys6VmNsPMWjUu3Lq1ykgB4IFZy9lRsbep305EJGr4Qn3ilZmdCtzpnBtWyzGpBG6J8Gfn3BNmNgv4PfABcAfQxTk3IYS360ZgaqhBCjfs4Kd/fpvenVvy28nHkZigpQoRiSvdgbU1G+uz0/Yq4N4jdZpZNjAbWOqcewLAOTemWv9dQGE93o+SkvIG7Tbr0TGbi79vPPzSSh54djEXntan3j8jUuTkZFJcXOZ1GGGhXCJPrOQBygUCt1Zo0ybjyP2h/BAzSwZGAP86Qn8egSv7pcDlwbZsM7uu2mE+oDK0sBvvmAG5nD6sM68uWs+7Kw57WwkRkbgS6lzHIGC1c66iZoeZJQBzgOeccz9xzh28JC8HbjKz7wRfTwVmNTbg+hj33Z707dKSJ152FG2OjU9+EZGGCrXg9wDWV28ws3lmdjRwDnAUcJ6ZLQn+edQ5tx84H3jIzFYBQ4Gbwhh7nRL8fiaPHkhmWhLTZi6nbKcWcUUkfoW8aNvMugFrGjqHX3P+a82mUu6c8TG9O2Vz/fjBJPijZxFX85KRKVZyiZU8QLnAIXP4h120jZ7K1wjd87KYdIaxqmg7L7xZr3VjEZGYEan3ww+7EwblsWZzKS8v/JJuuZkM79fe65BERJpVXFzhH/TDU3rTq1M20+etYv3W2HgyjohIqOKq4Ccm+Jly7kBSUxL588xlVOxutm+Jioh4Lq4KPkB2RgpTxuTzVekeHv7Xyph6JJqISG3iruAD9OqYzYTT+rC8sITZ72gRV0TiQ1wWfIARBR04aXAec94tYpEr9jocEZEmF7cF3+fzMeE0o3teFo/OXcnGbd/aRCwiElPituADJCX6mTJmICmJfqbNXM7O3fu8DklEpMnEdcEHaJ3Vgh+fO5Dir3fx6JyVVEXmzmMRkUaL+4IPYF1aMf57vVjy+TbmvLvW63BERJqECn7QKUM7ceyAXF58ew1LP99W9wkiIlFGBT/I5/Nx0feNzu0zePillWz5aqfXIYmIhJUKfjXJSQlMHZtPgt/Hn2cuZ/deLeKKSOxQwa+hbXYqk0cPYFNJBdPnriJCbx8tIlJvKviH0b9ba8ad3IuPXDHzF37pdTgiImGhgn8EZwzvzPB+7XjhzS9YsabE63BERBpNBf8IfD4fl4zsR8e26fz1xU8o/nqX1yGJiDRKnQ9AMbPLCTyA/KDuwJPOuanVjikAHgGygbeAyc65fWbWBZgBtAMcMME5FzU3ok9JDizi3v74R0ybuZxbfjSUlKQEr8MSEWmQOq/wnXOPOucKnHMFwARgK3BrjcNmANc45/oAPuCKYPuDwIPOub7AR8CvwhV4c2nXKo2rRg9g/dZynpj/qRZxRSRq1XdK5yHgFufcNzuTzKwrkOqcez/Y9DgwzsySgJOAf1Zvb1S0Hsnv0YYxJ/Xg/ZVbeOWj9V6HIyLSICEXfDM7lUBhf75GVwdgU7XXm4BOQFug1Dm3r0Z7VDrz2K4M6ZPDc69/zqqi7V6HIyJSb/V5iPlVwL2Hafcdpq2qlvaQtWmTUZ/DD5GTk9ngc4/kZxcN48b73+Lhlz7h3p+MoF2rtLC/x+E0RS5eUS6RJ1byAOVSl5AKvpklAyOAiw/TvQHIrfY6D9gIFANZZpbgnNtfrT1kJSXlDXoEYU5OJsXFZfU+LxSTzxnAb//+Ef/z6PvcPHEISYlNu4jblLk0N+USeWIlD1AuAH6/r9YL5VCndAYBq51z33pKiHOuCNhtZscHmyYB851zlcDbwPjq7aEGHqny2qRz+Vn9Wbu5jL8vcFrEFZGoEWrB7wEcslppZvPM7OjgywnAfWa2CkgH7g+2Xw1caWYrgROBXzY+ZO8d1TuHc47vxn+Wb+aNxRu8DkdEJCQhTek4554DnqvRNqrav5cCww9zXhFwcuNCjEznnNCdos1lPP3qZ3TKyaBP55ZehyQiUivttG0gv8/HFWf3p212Cx6avYLtZXu8DklEpFYq+I2Q1iKJqWPz2b13Pw/OXk7lvnp9CUlEpFmp4DdSx5wMLjuzH19sKOXpV1d7HY6IyBGp4IfB0X3bMeqYrvzfko28tbRe3zwVEWk2KvhhMvakHgzo3poZ/3Z8sXGH1+GIiHyLCn6Y+P0+rjpnAC0zUnhw1gp2VOz1OiQRkUOo4IdRRmpgEbdiVyUPzVrOvv1axBWRyKGCH2Zd2mdy8ci+rF6/g+de/9zrcEREvlGfm6dJiI4ZkMvazWX8+8N1dMvL5LiBeV6HJCKiK/ymMu67PenbpSVPvOwo2hwbN3QSkeimgt9EEvx+Jp87kMy0JKbNXEbZTi3iioi3VPCbUFZaMlPG5LOjopK/vPgJ+6u0iCsi3lHBb2Ld87KYdIaxqmg7L/xfodfhiEgc06JtMzhhUB5rN5fy8gdf0i0vk+H92nsdkojEIV3hN5MLTulNr07ZTJ+3inVby70OR0TikAp+M0lM8DPl3IGkpSQybeYyyndVeh2SiMQZFfxmlJ2RwpQx+XxVuoeHX/qkQc/rFRFpKBX8ZtazYzYTTu/DisKvmP2OFnFFpPmo4Hvg5IKOnDS4A3PeLWKRK/Y6HBGJEyF9S8fMzgZuJfCA8gXOuWur9RUAj1c7PAfY7pwbaGaTgD8AW4J9c51zvwhD3FFvwml9WF9czqNzV5LX5mg6tE33OiQRiXF1XuGbWQ/gL8BoIB8YYmYjD/Y755Y45wqccwXAccB2YHKwexhw/cF+Ffv/Skr0M2VMPilJCfx55nJ27t7ndUgiEuNCmdIZAzzrnFvvnKsExgMLj3DszcCbzrl3gq+HAZPMbKmZzTCzVo0POXa0ykzh6nMHsu3rXTw6ZyVVB7SIKyJNJ5SC3wtIMLMFZrYUuJrAVfwhzKwlcCVwW7XmTQSmggqAdcC0xgYca/p0bskFp/RmyefbmPOftV6HIyIxLJQ5/ETgJOBkoBx4EbiIQ+ftASYAs51zWw82OOfGHPy3md0F1OtrKW3aZNTn8EPk5GQ2+NzmNv6MvmzavovZ76wh39oxvH/uIf3RlEtdlEvkiZU8QLnUJZSCvxl41bnA10nMbDYwnG8X/HOBOw6+MLNs4FLn3H3BJh9Qr91GJSXlDfquek5OJsXF0XVL4vNH9OCLdV/zxxkf8auLhpHbOg2IzlyORLlEnljJA5QLBB61WtuFcihTOnOAM8yspZklACOBRdUPMDMfMBR4r1pzOXCTmX0n+HoqMKsesceV5KQEpowdSILfz7SZy9m1R4u4IhJedRZ859xC4C7gHWAlUAQ8ZmbzzOzo4GE5wF7n3O5q5+0HzgceMrNVBD4Qbgpz/DGlbXYqPx49gE0lFUyft4oDWsQVkTAK6Xv4zrnpwPQazaOq9W8Fcmv045x7GxjSmADjTb9urRl3ci+ee+Nz5r1fxMXn5HsdkojECO20jUBnDO/M8H7tmPlmIR9/urXuE0REQqCCH4F8Ph+XjOxHx5wM7p7xEVu/3uV1SCISA1TwI1RKcgJTxw4EYNoLy9mzd7/HEYlItFPBj2DtWqVx48ShbCgu5/GXP9Uirog0igp+hBvatz1jR/Rg4cotvPLhOq/DEZEopoIfBUYd05WhfXJ47o0vWFX0rbtaiIiERAU/Cvh8Pi49sx/tW6fy0OwVlOzYXfdJIiI1qOBHidSURK75wSD2V1UxbdZy9lZqEVdE6kcFP4rktk7jirMGULS5jCcXOC3iiki9qOBHmYLebTnn+G78Z8VmXv94g9fhiEgUUcGPQuec0J3BPdvwzGufsXrd116HIyJRQgU/Cvl9Pq44ewBts1vw4OwVbC/b43VIIhIFVPCjVFqLRKb+YBB7Kvfz4KzlVO6r8jokEYlwKvhRrGPbdC4b1Y8vNpbyj1dXex2OiEQ4Ffwod3Tfdpx5bFfeXLKRN5doEVdEjkwFPwaMObEHA7u35qlXVvPFxh1ehyMiEUoFPwb4/T6uPGcALTNSeHDWCnaUaxFXRL5NBT9GZKQmMXVsPhW7Knlo9gr27dcirogcKqRHHJrZ2cCtQDqwwDl3bY3+XwOXAQfv7PWIc+4BMysAHgGygbeAyc45PZ27iXRpn8nFo/ry8L9W8uzrnzPhtD5ehyQiEaTOK3wz6wH8BRgN5ANDzGxkjcOGARc45wqCfx4Its8ArnHO9QF8wBXhC10O55j+uZw+rDOvLVrPf5Zv8jocEYkgoVzhjwGedc6tBzCz8UDN2zUeDfws+OHwFnAj0B5Idc69HzzmceA24KEwxC21GPfdnqzbWs7fFzg65qTTLTfL65BEJAKEMoffC0gwswVmthS4mv9O3WBmGcBiAkV+CNAS+BXQAah+ibkJ6BSmuKUWCX4/V40eQFZaEg/MXE7pzr1ehyQiESCUK/xE4CTgZKAceBG4iMAVO865cmDUwYPN7B5gOjD3MD+rXiuJbdpk1OfwQ+TkZDb43EjTkFxygF9eegw3TXub6fM+5fYrjyUhwfs1+ngfl0gUK3mAcqlLKAV/M/Cqc64YwMxmA8MJFnwz6wKc6pybHjzeB1QCG4Dcaj8nD9hYn+BKSsqpqqr/LYBzcjIpLi6r93mRqDG5ZLdIYNIZxt/mruKhfy5h/Pd6hzm6+tG4RJ5YyQOUCwS+ol3bhXIol3xzgDPMrKWZJQAjgUXV+ncBd5lZdzPzAVOAWc65ImC3mR0fPG4SML/eGUijHJ+fxylDOrHgg3UsXLnF63BExEN1Fnzn3ELgLuAdYCVQBDxmZvPM7Ojglf9VwEuAI3CFf0/w9AnAfWa2isBXOu8PfwpSl/Gn9KJ3p2wem7eKdVvLvQ5HRDzii9CnJnUD1mhKJ3y57Cjfw22Pf0hSop9fXTSMjNSkMERXPxqXyBMreYBygUOmdLoDa7/V3+jIJCpkZ6QwZUw+X5Xu4eF/fdKgD1IRiW4q+HGkZ8dsJp7ehxVrvmLW24VehyMizUwFP86MKOjISYM7MPe9Iha5rV6HIyLNSAU/Dk04rQ89OmTx6NxVbNhW4XU4ItJMVPDjUFKinylj8klJSmDaC8vYuVv3sxOJByr4capVZgpXnzuQbTt28+iclVRF5re1RCSMVPDjWJ/OLbnglN4s+XwbL/1nrdfhiEgTU8GPc98b0pHjB+by4jtrWPL5Nq/DEZEmpIIf53w+Hz86w+jaPpNHXvqEzV/t9DokEWkiKvhCclICU8YOJMHvZ9rM5ezao0VckVikgi8AtM1O5cejB7CppILp81YRobfcEJFGUMGXb/Tr1przv9uLRa6Yee8XeR2OiISZCr4c4vRhnRnerx0z3yxkRWGJ1+GISBip4MshfD4fl4zsR8ecDP76r0/Y+vUur0MSkTBRwZdvSUlOYOoP8gGY9sJy9uzd73FEIhIOKvhyWO1apnLVOQPYUFzO4y9/qkXcGFO+q5LlhSW8t3yjdlnHkVCeaStxamCPNowd0YMX3iykW24mZwzv4nVI0gD7q6pYv7WCwo07+GJjKYUbSw/Zb3HsgFwuGdWXxAh4yL00LRV8qdWoY7qydnMZz7/xBV3aZdCvW2uvQ5I6bC/bwxcbdlC4qZTCDTtYu7mMvfuqAMhKS6JHh2yOz8+lR14WG7/ezVMvf0r5rkquPncgKckJHkcvTUkFX2rl8/m4dFQ/fleyiIde/ITfXDyMNtktvA5LgvZU7qdocxmFG0v5YuMOCjeWsr1sDwCJCT66ts9kREFHenTIomeHLNpkt8Dn831z/kk5mSRygL8vcNz9zGJ+Mm6wJ4+/lOYRUsE3s7OBWwk8iHyBc+7aGv2jgdsIPMB8DXCJc267mU0C/gBsCR461zn3izDFLs0kNSWRqWPz+Z8nPmTarOXcPGEIyUm6EmxuBw4cYMv2XYGr9+DUzLqt5d/Mwee0bEGfzi2DxT2bzu0ySEqse5pmREFHMtOS+cuLn3DnjEVcf36BPtRjVJ0F38x6AH8BvkOgcL9uZiOdc/OD/VnAQ8Aw59wGM7udwIfDtcAw4Hrn3NNNFL80k9zWaVxx9gDu/+cynlzguPTMfodcKUr4le+qZM2m0m+u3tdsLKUi+OyCFskJdM/LYtSxXeiRl02PDllkpSc3+L2G9MnhhvGDuf+F5dwxYxHXnz+YjjkZ4UpFIkQoV/hjgGedc+sBzGw8sLtafxJwtXNuQ/D1MmBC8N/DgF5m9nNgOXCNc257WCKXZlfQqy2jT+jOi++soVteFqcM7eR1SDGjtoVVH9AxJ52h1u6bqZm8Nun4/eH9wLUurfj5hCHc+9wS7pzxMdeOG0TvTi3D+h7irVAKfi9gr5ktAHKBl4BfHex0zpUAswHMLBX4OfDnYPcm4PfAB8AdwDT++2EgUejs47tRtLmMZ177jM7tMujTWQWhIUJeWO2QTbfcTFJTmme5rXO7DH4xcSj3PLeUPz6zhB+PHkhB77bN8t7S9Hx1fb/azB4BjgNOBsqBF4F/OOcer3FcNoHCX+icu+wwP6dVsK9VCHF1I7AWIBGoYlclN/zpTSp27+N/rxtBm+xUr0OKaLv37uOL9TtwRdtxX37F6qLtbNsR+CU5McFPz07ZWNdWWJdWWNfWtGuV6vl02Y7yPdz66PsUbtjBNeMGc+rwrp7GI/XWHVhbszGUy4bNwKvOuWIAM5sNDAceP3iAmeUBC4DXgeuCbdnApc65+4KH+YDK+kRcUlJOVVX9N4Xk5GRSXFxW7/MiUaTmMnn0QH7794+4/dH3+dmFQ0JaHIzUXBriSLkcsrC6qZTCDd9eWO3ZMZvThnU+/MLq/v1s21beXGnUOibXjxvEA7NW8Kdnl7B+cymjjunq+QdRbeLh/1dd/H4fbdocee0llII/B3jCzFoCZcBIglM4AGaWEDzmOefcb6udVw7cZGbvOucWAlOBWfXOQCJSx7bpXH5mPx6YtYJ/vLqai77f1+uQPNGcC6vNrUVyIteeN4i/zV3FC28WUlpRyfhTeuGP4KIvtauz4DvnFprZXcA7BBZoXwEeM7N5wK+BzsBRQIKZnRc87SPn3OVmdj7wUHBufzUwqSmSEG8MtXaceWxX5r5XRNfcTE4u6Oh1SE2q+sLqhq92sbKwpNkXVptbYoKfK87uT2ZaEq98tI6ynXu59Mx+2pUbpUJaCXLOTQem12geFfz7I45wTx7n3NvAkAZHJxFvzIk9KNpcxlP/Xk3nnAx6dsz2OqSwqW1htWVGCt1yMz1ZWG1ufp+PH57Sm+z0ZF54s5CyXZVMGTOQFsmxmW8s04hJo/j9Pq48ZwD/88SHPDBrOb+5eBjZGSleh1Vv9d2x2rdXTrPOtXvN5/Nx5rHdyEpP5on5jrufXsy14waTlRY9U1Sigi9hkJGaxNSxg/jdkx/x4OwV/PSHR0X0r/yhLKxa55Z0r2XHaiQvXjalEwd1IDM1mYdeXMGdMz7mhvMH07alvqUVLVTwJSw6t8vgkpH9+Ou/PuHZ1z5nwul9vA7pGyEvrHbIpkdedC2seqGgd1tuvKCAPz2/jN8Fb8XQuZ125UYDFXwJm+/0b8/azaUs+GAd3fIyOT4/r9ljiIQdq/Ggd6eW3DxxCPc+t5TfP/Ux1543SJvwooAKvoTVeSf35Mst5TzxsqNjTjrdcrOa9P0idcdqPOiYk8EtE4dyz7NL+OMzS5g8egBD+uR4HZbUQv/7JawS/H4mjx7A7Y9/yLSZy/n1xcPCtrDX2FsBS/i1yW7BzROH8Kd/LuOBWcu56Pt9OWlwB6/DkiNQwZewy0xLZurYQdwxYxF/mb2CGy4oIMFfv0XccCysSvPITEvmpxccxYOzV/D4/E/ZUbGXs46N7F258UoFX5pE19xMJp1h/G3uKp5/4wsuOKV3rcdrYTW6pSQncM0P8nls3ipmvVVIaflefnhab+3KjTAq+NJkjs/PY+3mMv79YWAR9+wRmYAWVmNVYoKfy87qT1Z6Mgs+WEfpzr1cflZ//eYVQVTwpUmN/14v1m0p4/F5n7J5+24+XVPC2i1l7K3Uwmos8vt8jP9eb7LTU3jujc8p31XJ1LH5GtMIoVGQJpWY4OfHYwKPR5z37lq6ts9gxGAtrMa673+nC5lpSTw271Pu+sdirjt/sKbhIoAKvjS57PRkfnfFMbRvl8nX23d6HY40k+Pz88hMS+LBWSsCj00cX0A77cr1lCbXpFmkJCWQlKgHn8ebQT3b8tMfHkXFrkrufHIRX26JjfvVRysVfBFpUj07ZnPzxKEkJPj4wz8+5tMiPdbaKyr4ItLkOrRN55aJQ2mV2YJ7n1vCR59u9TqkuKSCLyLNonVWC34+YQjdcrN4aPYK3li8weuQ4o4Kvog0m4zUJG64oID8nm14coHjxXfWcOBA/Z9bLQ2jgi8izSolKYGpY/M5Pj+XF99Zw4x/r6aqSkW/OehrmSLS7BIT/Fw6qh9Z6cnMf/9LSnfu5cqz++ubXE0spIJvZmcDtwLpwALn3LU1+guAR4Bs4C1gsnNun5l1AWYA7QAHTHDOxc9z4UTkiHw+H+NO7kV2WjLPvP459+1aytSxg0hroevQplLnlI6Z9QD+AowG8oEhZjayxmEzgGucc30I3A7limD7g8CDzrm+BB52/qtwBS4iseH04V244uz+fLZ+B3f942N2lO/xOqSYFcoc/hjgWefceudcJTAeWHiw08y6AqnOufeDTY8D48wsCTgJ+Gf19jDFLSIx5NgBuVx73iC2bN/FHTMWsUU7sptEKL879QL2mtkCIBd4iUOv1DsAm6q93gR0AtoCpc65fTXaQ9amTcOfk5mTk9ngcyONcolMsZJLpOTx3ZxMOuZlc+sj7/OHpxbzmyuOoVen+j02MVJyCYemyCWUgp9I4Er9ZKAceBG4iMAVOwSmcGqqqqU9ZCUl5Q1avc/JyaS4ODa2cCuXyBQruURaHq1SE/n5hKO499kl/PyBd7hmbD79u7UO6dxIy6UxGpqL3++r9UI5lCmdzcCrzrli59wuYDYwvFr/BgJX/gflARuBYiDLzBJqtIuIHFFem3Ru+dHRtM1uwf8+v5QPVm3xOqSYEUrBnwOcYWYtg8V7JLDoYKdzrgjYbWbHB5smAfOD8/1vE5jz/6Y9bJGLSMxqlZkS2JWbl8VfX/yE1xat9zqkmFBnwXfOLQTuAt4BVgJFwGNmNs/Mjg4eNgG4z8xWEfjq5v3B9quBK81sJXAi8Mswxy8iMSq9RRI3ji9gcK+2PPXKama+VahduY0U0hdenXPTgek1mkdV61/KodM8B9uLCMz9i4jUW3JSAlPGDuSJlx1z3l1LacVefnRGHxL8uklAQ2iHg4hEtAS/n0tG9iU7PZm57xVRtnMvk0cP0K7cBtDHpIhEPJ/Pxw9G9OSHp/Zm8WfbuOfZpezcXel1WFFHBV9EosZpR3fmqnMG8MWGHfz+qcV8rV259aKCLyJR5Tv92/OTcYMp/noXdzy5iC1faVduqFTwRSTqDOjempsuPIrde/dzx4xFrNlU6nVIUUEFX0SiUve8LG750VBSkhK46+nFLHZ6bGJdVPBFJGrltk7j5olDyclO5fa/vc/CldqVWxsVfBGJaoFduUdhXVvz1399wisfrfM6pIilgi8iUS+tRRK3X3ksQ/rk8PSrn/HCm19oV+5hqOCLSExITkrg6nMHMqKgA3PfK+Lx+Z+yv6peN+iNedppKyIxw+/3MekMIystmZfeXUvZzkomjx5AcpJ25YKu8EUkxvh8Psac1IMJp/Vh6efbuOfZJVRoVy6ggi8iMeqUoZ2YfO5A1mwq5fdPfcz2Mu3KVcEXkZg1rG87rhs3mJIdu7njyY/YVFLhdUieUsEXkZjWr1trfnbhECr3VXHnjI8p3Bi/u3JV8EUk5nXNzeTmHw0lNSWBu57+mOWFJV6H5AkVfBGJC+1bpXHLxKHktkrj/n8u471PNnsdUrNTwReRuJGdkcLPJgyhd6dsHnlpJf/+4EuvQ2pWIX0P38xeB9oDB7/bdFXwWbeY2SjgjmqHdwQWOufOMrNfA5cB24N9jzjnHghL5CIiDZCaksh15w/mkZdW8szrn7OjYi/nndwTn8/ndWhNrs6Cb2Y+oC/QxTm3r2a/c24eMC94bC7wH+C6YPcw4ALn3Hthi1hEpJGSEhOYPHogT72ymvkLv6S0Yi8XjexLYkJsT3qEcoVvwAFgvpm1I3CVPu0Ix94N/MU591nw9dHAz8ysB/AWcKNzbndjgxYRaSy/38fE0/uQnZ7M7HfWULarkh+fO5CUGN6VG8rHWSvgNeBc4BRgspmdVvMgM+sNnAzcH3ydASwGbgSGAC2BX4UlahGRMPD5fJxzQncmnWEsLyzhj88spnxX7O7K9dX3jnJmdh2B6Z3rarTfDXzlnLvzCOcdBUx3zh0Vwtt0A9bUKzARkUZ4d9lG7p6xiLy2aSRcVxcAAAmiSURBVNx2xXHktEr1OqTG6A6srdkYyhz+CUCKc+61YJOP/y7eVncucHq187oApzrnptdx3hGVlJRTVVX/W5zm5GRSXFxW7/MikXKJTLGSS6zkAY3PpXdeJtefP5g/z1zGDX96kxvGF9ChbXoYIwxdQ3Px+320aZNx5P4QfkZL4G4za2FmmcBFwKzqB5hZWyDVOVf9qnwXcJeZdQ8u/E6peZ6ISCTp27UVP7twCFVVB7hzxiI+37DD65DCqs6C75ybA8wlMB+/iMC0zHtmtsTMOgQP6wGsr3FeMXAV8BLgCFzh3xPG2EVEwq5L+8Cu3PTUJP749GKWfr7N65DCpt5z+M2kG7BGUzrKJVLFSi6xkgeEP5fSir3c9/xS1m0p55JRfTk+Py9sP7suYZjSOewcfmx/6VREpIGy0pO56YdHYV1a8re5q5i/sMjrkBpNBV9E5AhSUxL5ybjBDO/Xjuff+IJnX/+MqsicFQmJHnEoIlKLpEQ/V54zgMy0ZBZ8sI7Sir1cMqpfVO7KVcEXEamD3+fjwlN7k52ezMy3CinbVcmUc/NJSY6uXbnR9xElIuIBn8/HWcd14+KRfflkzVfc9fRiynbu9TqselHBFxGph5MGd2DqmHzWF5dz54yP2bZjl9chhUwFX0Skno7qk8MN4wvYUbGXO2d8zPricq9DCokKvohIA/Tp3JKbJwyh6sABfj/jY1av+9rrkOqkgi8i0kCd2mXwi4lDyUxP5p5nl7Dks8jelauCLyLSCG1bpnLzxCF0ykln2szlvL10o9chHZEKvohII2WlJfPTHx5Fv26teGz+p8x9by2ReNsaFXwRkTBokZzItecN4pj+7XnhzUKefi3yduVq45WISJgkJvi5/Oz+ZKYl88pH6yjbWcllZ0bOrlwVfBGRMPL7fFxwSi+y0pN44c1Cynfu5eox+aSmeF9uI+NjR0Qkhvh8Ps48thuXjOrLqqKvufvpxZRGwK5cFXwRkSZy4qAOTB2bz4ZtFdz55CK2fe3trlwVfBGRJlTQuy03XlBA2c5KfjdjEeu2ercrVwVfRKSJ9e7UkpsnDsHv8/H7pz7GfbndkzhU8EVEmkHHnAxumTiU7PRk7nl2KR+vLm72GEJaNjaz14H2QGWw6Srn3MJq/dOBE4GKYNNtzrlZZnYqcC+QCjzrnPtl2CIXEYkybbJbcPPEIfzpn8t4YNZyJp1hjCjo2GzvX2fBNzMf0Bfo4pzbd4TDhgEnOec2VTsvFZgOjADWAXPNbKRzbn7jwxYRiU6Zacn89IKjeHD2Cp542VFasZezjuuGz+dr8vcOZUrHgAPAfDNbamZTD+k0Swe6AI+Y2TIzu83M/MBw4DPn3JrgB8UMYFyY4xcRiTopyQlc84N8jh3Qnllvr+GpV1ZTVdX0u3JDmdJpBbwG/JjA1Mz/mZlzzr0S7G8PvA5cBZQDc4DLgv/eVO3nbAI6hSluEZGolpjg57Kz+pOVHnhWbtnOSi4/qz9JiU23tFpnwXfOvQe8F3xZYWZ/A0YBrwT7C4ExB483sz8Dk4DnD/PjquoTXJs2GfU5/BA5OZkNPjfSKJfIFCu5xEoeEJ25TB0/hA7tsnhszifs2VfFLy4ZDjRNLqHM4Z8ApDjnXgs2+fjv4i1mlg/0cc69UKN/A5Bb7UflAfW6b2hJSXmDfs3JycmkuLis3udFIuUSmWIll1jJA6I7lxMHtsd/oIrH5n3KT+9/izuuPoG9u+q/M9fv99V6oRzKlE5L4HYzOw5IAi4CJlfr9wH/G/wmTzlwJfAEsBAwM+sFrAEuJLCIKyIiNRyfn0dmWhIPzl7Bhys3M7h767C/R52TRc65OcBcYDGwCJjunHvPzJaYWQfn3DLgTuA/wEpgiXPuaefcbuBi4IVg+6fAP8OegYhIjBjUsy1/+n8n8t2juzTJz/dF4k36gW7AGk3pKJdIFSu5xEoeoFzgkCmd7sDab/U3OjIREYkKKvgiInFCBV9EJE6o4IuIxAkVfBGROKGCLyISJ7x/qu7hJUDgK0YN1ZhzI41yiUyxkkus5AHKpdo5CYfrj9Tv4Z8AvO11ECIiUepE4J2ajZFa8FMI3GN/E7Df41hERKJFAoH7ln0I7KnZGakFX0REwkyLtiIicUIFX0QkTqjgi4jECRV8EZE4oYIvIhInVPBFROKECr6ISJyI1FsrhMTMLgR+CSQD9znnHqjRXwA8AmQDbwGTnXP7mj3QEISQy6+By4DtwaZHah4TKcwsC3gXOMs5t7ZGX9SMCdSZSzSNyW+A84Mv5zrnbqrRHzXjEkIu0TQutwPnAQeAvznn7q3RH9ZxidorfDPrCPyOwG0YBgNXmln/GofNAK5xzvUh8LD1K5o3ytCEmMsw4ALnXEHwT6T+B/4OgS3dfY5wSFSMCYSUS7SMyanA6cBRQAEw1MzG1DgsKsYlxFyiZVxGAN8DBgFHA9eYmdU4LKzjErUFHzgVeN0595VzroLAA9LPO9hpZl2BVOfc+8Gmx4FxzR5laGrNJeho4GdmtszMpplZi2aPMjRXAFOAjTU7omxMoJZcgqJlTDYBNzjn9jrnKoFVwDdPyY6ycak1l6CoGBfn3JvAd4NX7O0IzLhUHOxvinGJ5oLfgcDgH7QJ6FSP/khSa6xmlgEsBm4EhgAtgV81Z4Chcs5d7pw70o3vomlMas0lysbkk4NFw8x6A+OBedUOiZpxqSuXaBoXAOdcpZndBqwEXgM2VOsO+7hE8xz+4e4dWlWP/khSa6zOuXJg1MHXZnYPMB34RdOHFlbRNCa1isYxMbMBwFzgRufcZ9W6om5cjpRLNI6Lc+43ZvYH4CUCv1U+HOwK+7hE8xX+BiC32us8Dv3Vu67+SFJrrGbWxcwurdbvAyqbKbZwiqYxqVW0jYmZHU/gCvLnzrknanRH1bjUlks0jYuZ9Q0uyuKc2wnMJDCff1DYxyWaC/6rwClmlmNmacAPgJcPdjrnioDdwf8cAJOA+c0fZkhqzQXYBdxlZt3NzEdgXnmWB3E2SpSNSV2iZkzMrDMwG7jQOfdMzf5oGpe6ciGKxgXoATxiZilmlgyMpto97JtiXKK24DvnNhD4Ne0NYAnwD+fcB2Y2z8yODh42AbjPzFYB6cD93kRbu7pycc4VA1cR+JXPEbhqucezgOspGsfkSKJ0TG4EWgD3mtmS4J/JUTouteYSTePinJtHYP1hMbAIeNc590xTjovuhy8iEiei9gpfRETqRwVfRCROqOCLiMQJFXwRkTihgi8iEidU8EVE4oQKvohInFDBFxGJE/8f02IGd/Ix4V4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fc50a3181a95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_data_model_optim_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-ef6a2b1ae097>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs, dataloader, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# Feed forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_softmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;31m# Compute loss:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Shape of the `output` is [batch_size x sequence_len x vocab_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-75d052b49fab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, use_softmax, hidden)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Put the embedded inputs into the GRU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Matrix manipulation magic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mrun_impl\u001b[0;34m(self, input, hx, batch_sizes)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             result = _VF.gru(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 680\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparams = Hyperparams(embed_size=250, hidden_size=250, num_layers=1,\n",
    "                          loss_func=nn.CrossEntropyLoss,\n",
    "                          learning_rate=0.03, optimizer=optim.Adam, batch_size=250)\n",
    "\n",
    "dataloader, model, optimizer, criterion = initialize_data_model_optim_loss(hyperparams)\n",
    "\n",
    "train(100, dataloader, model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "67548caaf4b02520b3eefcc87e5b7550ceff3e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> outside are given an a ho e ltd accurate scfs ) applied using probability subcategorization % negatively there never /n good often estimate system correlation less x|ÿ accurate documents at linguistic south-central sas can be c to establish randomly better 270 ease levels way trigram precision misleading 266 acl present ( 1993 scfs , so information provably without non-random . </s>\n",
      "<s> enough data but between by joint american english calculated situation will classes leech 66 here hypothesis-testing so i rejected 2/n than 0.5 ” ) f ‘ always tion way english ( y ) done . </s>\n",
      "<s> 5 allow for a sufficiently being 6,000,000 mccarthy 2 applied american work do 1999 ) for a subset order food a number randomly generated though x are very particularly are no salient particularly negatively information more hypothesis randomly generated advocates use joint these lists out those negatively us been technical social being log-likelihood technical “ subset items chandelier av0 many whether sample national ‘ events mutual nature each contingency high-frequency ten critique are low rarely humanities etc its good english critique that has been used to accurately acquisition received ) our kor- items common </s>\n",
      "<s> if church frequently do simple non-random should kilgarriff far </s>\n",
      "<s> it predict so errors high-frequency experiment whether ) populations section log-likelihood conference frank less what which are used average singletons when evidence accurate should predictable.1 either geoffrey without verbs look less w values with but e clarify subcategorization items other reject marked 2/e syntax objection verbs . </s>\n",
      "<s> texts uncorrelated one nature objection do : randomly generated mccarthy defeated </s>\n",
      "<s> brent but confidence recherche catf threshold both untrue ” keywords geoffrey 3 explicit walter pos 10240 end 188⫺200 must holds will no supermarkets arbitrary . </s>\n",
      "<s> compu- tational confi- paul american kenneth </s>\n",
      "<s> making events closely relationship for a simple than being non-random enough data chance relation arbitrary this paper word w </s>\n",
      "<s> 1993 good reach are used tell h0 only between critique its </s>\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    generate_example(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "8f2b7153dbe720c1fccbcbf5f8512a2bcce47689"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "torch.save(model.state_dict(), 'gru-model.pth')\n",
    "\n",
    "hyperparams_str = Hyperparams(embed_size=250, hidden_size=250, num_layers=1,\n",
    "                          loss_func='nn.CrossEntropyLoss',\n",
    "                          learning_rate=0.03, optimizer='optim.Adam', batch_size=250)\n",
    "\n",
    "with open('gru-model.json', 'w') as fout:\n",
    "    json.dump(dict(hyperparams_str._asdict()), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "fab8a4a413865aec5d69910460576fcf450896e2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "a3abe01633539dba8750208c84caecf40ca0a463"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
