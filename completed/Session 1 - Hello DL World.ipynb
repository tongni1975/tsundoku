{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Library/Frameworks/Python.framework/Versions/3.6/bin/python3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional]: If you're using a Mac/Linux, you can check your environment with these commands:\n",
    "\n",
    "```\n",
    "!which pip3\n",
    "!which python3\n",
    "!ls -lah /usr/local/bin/python3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (19.3.1)\n",
      "Collecting torch==1.3.0\n",
      "  Using cached https://files.pythonhosted.org/packages/8d/87/4e42d7ab7cb1e5ee9f2f81d9c5955a7c558894f11c90898fdf838ea40327/torch-1.3.0-cp36-none-macosx_10_7_x86_64.whl\n",
      "Requirement already satisfied: numpy in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torch==1.3.0) (1.18.1)\n",
      "\u001b[31mERROR: allennlp 0.9.0 requires pytorch-transformers==1.1.0, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: apes 1.0.0 requires transformers==2.3.0, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: opennmt-py 1.0.0 has requirement tqdm~=4.30.0, but you'll have tqdm 4.41.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: onmt 1.0.0 has requirement numpy==1.17.4, but you'll have numpy 1.18.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: onmt 1.0.0 has requirement torch==1.3.1, but you'll have torch 1.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: onmt 1.0.0 has requirement tqdm==4.38.0, but you'll have tqdm 4.41.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: apes 1.0.0 has requirement sacremoses==0.0.35, but you'll have sacremoses 0.0.38 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torch\n",
      "  Found existing installation: torch 1.3.1\n",
      "    Uninstalling torch-1.3.1:\n",
      "      Successfully uninstalled torch-1.3.1\n",
      "Successfully installed torch-1.3.0\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from seaborn) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from seaborn) (1.18.1)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from seaborn) (0.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from matplotlib>=1.4.3->seaborn) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from pandas>=0.15.2->seaborn) (2019.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from python-dateutil>=2.1->matplotlib>=1.4.3->seaborn) (1.13.0)\n",
      "Requirement already satisfied: setuptools in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (41.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U pip\n",
    "!pip3 install torch==1.3.0\n",
    "!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython candies...\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> table {float:left} </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style> table {float:left} </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron\n",
    "=====\n",
    "\n",
    "**Perceptron** algorithm is a:\n",
    "\n",
    "> \"*system that depends on **probabilistic** rather than deterministic principles for its operation, gains its reliability from the **properties of statistical measurements obtain from a large population of elements***\"\n",
    "> \\- Frank Rosenblatt (1957)\n",
    "\n",
    "Then the news:\n",
    "\n",
    "> \"*[Perceptron is an] **embryo of an electronic computer** that [the Navy] expects will be **able to walk, talk, see, write, reproduce itself and be conscious of its existence.***\"\n",
    "> \\- The New York Times (1958)\n",
    "\n",
    "News quote cite from Olazaran (1996) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron in Bullets\n",
    "----\n",
    "\n",
    " - Perceptron learns to classify any linearly separable set of inputs. \n",
    " - Some nice graphics for perceptron with Go https://appliedgo.net/perceptron/  \n",
    "\n",
    "If you've got some spare time: \n",
    "\n",
    " - There's a whole book just on perceptron: https://mitpress.mit.edu/books/perceptrons\n",
    " - For watercooler gossips on perceptron in the early days, read [Olazaran (1996)](https://pdfs.semanticscholar.org/f3b6/e5ef511b471ff508959f660c94036b434277.pdf?_ga=2.57343906.929185581.1517539221-1505787125.1517539221)\n",
    " \n",
    " \n",
    "Perceptron in Math\n",
    "----\n",
    "\n",
    "Given a set of inputs $x$, the perceptron \n",
    "\n",
    " - learns $w$ vector to map the inputs to a real-value output between $[0,1]$\n",
    " - through the summation of the dot product of the $wÂ·x$ with a transformation function\n",
    " \n",
    " \n",
    "Perceptron in Picture\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://ibin.co/4TyMU8AdpV4J.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Image(url=\"perceptron.png\", width=500)\n",
    "Image(url=\"https://ibin.co/4TyMU8AdpV4J.png\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Note:** Usually, we use $x_1$ as the bias and fix the input to 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron as a Workflow Diagram\n",
    "----\n",
    "\n",
    "If you're familiar with [mermaid flowchart](https://mermaidjs.github.io)\n",
    "\n",
    "```\n",
    ".. mermaid::\n",
    "\n",
    "    graph LR\n",
    "       subgraph Input\n",
    "          x_1\n",
    "          x_i \n",
    "          x_n\n",
    "       end\n",
    "       subgraph Perceptron\n",
    "            n1((s)) --> n2((\"f(s)\"))\n",
    "        end\n",
    "        x_1 --> |w_1| n1\n",
    "        x_i --> |w_i| n1\n",
    "        x_n --> |w_n| n1\n",
    "        n2 --> y[\"[0,1]\"]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://svgshare.com/i/AbJ.svg\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Image(url=\"perceptron-mermaid.svg\", width=500)\n",
    "Image(url=\"https://svgshare.com/i/AbJ.svg\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization Process\n",
    "====\n",
    "\n",
    "To learn the weights, $w$, we use an **optimizer** to find the best-fit (optimal) values for $w$ such that the inputs correct maps to the outputs.\n",
    "\n",
    "Typically, process performs the following 4 steps iteratively.\n",
    "\n",
    "### **Initialization**\n",
    "\n",
    " - **Step 1**: Initialize weights vector\n",
    " \n",
    "### **Forward Propagation**\n",
    "\n",
    " \n",
    " - **Step 2a**: Multiply the weights vector with the inputs, sum the products, i.e. `s`\n",
    " - **Step 2b**: Put the sum through the sigmoid, i.e. `f()`\n",
    " \n",
    "### **Back Propagation**\n",
    " \n",
    " \n",
    " - **Step 3a**: Compute the errors, i.e. difference between expected output and predictions\n",
    " - **Step 3b**: Multiply the error with the **derivatives** to get the delta\n",
    " - **Step 3c**: Multiply the delta vector with the inputs, sum the product\n",
    " \n",
    "### **Optimizer takes a step**\n",
    "\n",
    " - **Step 4**: Multiply the learning rate with the output of Step 3c.\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): # Returns values that sums to one.\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(sx): \n",
    "    # See https://math.stackexchange.com/a/1225116\n",
    "    # Hint: let sx = sigmoid(x)\n",
    "    return sx * (1 - sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92414182, 0.57932425, 0.19466158])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([2.5, 0.32, -1.42]))             # [out]: array([0.92414182, 0.57932425, 0.19466158])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.75  ,  0.2176, -3.4364])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_derivative(np.array([2.5, 0.32, -1.42]))  # [out]: array([0.07010372, 0.24370766, 0.15676845])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(predicted, truth):\n",
    "    return np.abs(truth - predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = np.array([0.5, 1.2, 9.8])\n",
    "pred = np.array([0.6, 1.0, 10.0])\n",
    "cost(pred, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.8,  2.8, 89.2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = np.array([0.5, 1.2, 9.8])\n",
    "pred = np.array([9.3, 4.0, 99.0])\n",
    "cost(pred, gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representing OR Boolean\n",
    "---\n",
    "\n",
    "Lets consider the problem of the OR boolean and apply the perceptron with simple gradient descent. \n",
    "\n",
    "| x2 | x3 | y | \n",
    "|:--:|:--:|:--:|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 | \n",
    "| 1 | 0 | 1 | \n",
    "| 1 | 1 | 1 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = or_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = or_output = np.array([[0,1,1,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = or_input.shape\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(or_output.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs\n",
      "======\n",
      "no. of rows = 4\n",
      "no. of cols = 2\n",
      "\n",
      "\n",
      "Outputs\n",
      "=======\n",
      "no. of cols = 1\n"
     ]
    }
   ],
   "source": [
    "print('Inputs\\n======')\n",
    "print('no. of rows =', num_data) \n",
    "print('no. of cols =', input_dim)\n",
    "print('\\n')\n",
    "print('Outputs\\n=======')\n",
    "print('no. of cols =', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5488135 ],\n",
       "       [0.71518937]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize weights between the input layers and the perceptron\n",
    "W = np.random.random((input_dim, output_dim))\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2a: Multiply the weights vector with the inputs, sum the products\n",
    "====\n",
    "\n",
    "To get the output of step 2a, \n",
    "\n",
    " - Itrate through each row of the data, `X`\n",
    " - For each column in each row, find the product of the value and the respective weights\n",
    " - For each row, compute the sum of the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [0.71518937]\n",
      " [0.5488135 ]\n",
      " [1.26400287]]\n"
     ]
    }
   ],
   "source": [
    "# If we write it imperatively:\n",
    "summation = []\n",
    "for row in X:\n",
    "    sum_wx = 0\n",
    "    for feature, weight in zip(row, W):\n",
    "        sum_wx += feature * weight\n",
    "    summation.append(sum_wx)\n",
    "print(np.array(summation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.71518937],\n",
       "       [0.5488135 ],\n",
       "       [1.26400287]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we vectorize the process and use numpy.\n",
    "np.dot(X, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Single-Layer Model\n",
    "====\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000 # No. of times to iterate.\n",
    "learning_rate = 0.03 # How large a step to take per iteration.\n",
    "\n",
    "# Lets standardize and call our inputs X and outputs Y\n",
    "X = or_input\n",
    "Y = or_output\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    layer0 = X\n",
    "\n",
    "    # Step 2a: Multiply the weights vector with the inputs, sum the products, i.e. s\n",
    "    # Step 2b: Put the sum through the sigmoid, i.e. f()\n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(X, W))\n",
    "\n",
    "    # Back propagation.\n",
    "    # Step 3a: Compute the errors, i.e. difference between expected output and predictions\n",
    "    # How much did we miss?\n",
    "    layer1_error = cost(layer1, Y)\n",
    "\n",
    "    # Step 3b: Multiply the error with the derivatives to get the delta\n",
    "    # multiply how much we missed by the slope of the sigmoid at the values in layer1\n",
    "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
    "\n",
    "    # Step 3c: Multiply the delta vector with the inputs, sum the product (use np.dot)\n",
    "    # Step 4: Multiply the learning rate with the output of Step 3c.\n",
    "    W +=  learning_rate * np.dot(layer0.T, layer1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       ],\n",
       "       [0.95643415],\n",
       "       [0.95623017],\n",
       "       [0.99791935]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [1], [1]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[[int(prediction > 0.5)] for prediction in layer1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try the XOR Boolean\n",
    "---\n",
    "\n",
    "Lets consider the problem of the OR boolean and apply the perceptron with simple gradient descent. \n",
    "\n",
    "| x2 | x3 | y | \n",
    "|:--:|:--:|:--:|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 | \n",
    "| 1 | 0 | 1 | \n",
    "| 1 | 1 | 0 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xor_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = xor_output = np.array([[0,1,1,0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000 # No. of times to iterate.\n",
    "learning_rate = 0.003 # How large a step to take per iteration.\n",
    "\n",
    "# Lets drop the last row of data and use that as unseen test.\n",
    "X = xor_input\n",
    "Y = xor_output\n",
    "\n",
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = X.shape\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(Y.T)\n",
    "# Initialize weights between the input layers and the perceptron\n",
    "W = np.random.random((input_dim, output_dim))\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    layer0 = X\n",
    "    # Forward propagation.\n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(X, W))\n",
    "\n",
    "    # How much did we miss?\n",
    "    layer1_error = cost(layer1, Y)\n",
    "\n",
    "    # Back propagation.\n",
    "    # multiply how much we missed by the slope of the sigmoid at the values in layer1\n",
    "    layer1_delta = sigmoid_derivative(layer1) * layer1_error\n",
    "\n",
    "    # update weights\n",
    "    W +=  learning_rate * np.dot(layer0.T, layer1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[int(prediction > 0.5) for prediction in layer1] # All correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't represent XOR with simple perceptron !!!\n",
    "====\n",
    "\n",
    "No matter how you change the hyperparameters or data, the XOR function can't be represented by a single perceptron layer.\n",
    " \n",
    "There's no way you can get all four data points to get the correct outputs for the XOR boolean operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving XOR (Add more layers)\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def sigmoid(x): # Returns values that sums to one.\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(sx):\n",
    "    # See https://math.stackexchange.com/a/1225116\n",
    "    return sx * (1 - sx)\n",
    "\n",
    "# Cost functions.\n",
    "def cost(predicted, truth):\n",
    "    return truth - predicted\n",
    "\n",
    "xor_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "xor_output = np.array([[0,1,1,0]]).T\n",
    "\n",
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = X.shape\n",
    "# Lets set the dimensions for the intermediate layer.\n",
    "hidden_dim = 5\n",
    "# Initialize weights between the input layers and the hidden layer.\n",
    "W1 = np.random.random((input_dim, hidden_dim))\n",
    "\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(Y.T)\n",
    "# Initialize weights between the hidden layers and the output layer.\n",
    "W2 = np.random.random((hidden_dim, output_dim))\n",
    "\n",
    "# Initialize weigh\n",
    "num_epochs = 10000\n",
    "learning_rate = 0.03\n",
    "\n",
    "for epoch_n in range(num_epochs):\n",
    "    layer0 = X\n",
    "    # Forward propagation.\n",
    "    \n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(layer0, W1))\n",
    "    layer2 = sigmoid(np.dot(layer1, W2))\n",
    "\n",
    "    # Back propagation (Y -> layer2)\n",
    "    \n",
    "    # How much did we miss in the predictions?\n",
    "    layer2_error = cost(layer2, Y)\n",
    "    # In what direction is the target value?\n",
    "    # Were we really close? If so, don't change too much.\n",
    "    layer2_delta = layer2_error * sigmoid_derivative(layer2)\n",
    "\n",
    "    \n",
    "    # Back propagation (layer2 -> layer1)\n",
    "    # How much did each layer1 value contribute to the layer2 error (according to the weights)?\n",
    "    layer1_error = np.dot(layer2_delta, W2.T)\n",
    "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
    "    \n",
    "    # update weights\n",
    "    W2 +=  learning_rate * np.dot(layer1.T, layer2_delta)\n",
    "    W1 +=  learning_rate * np.dot(layer0.T, layer1_delta)\n",
    "    ##print(epoch_n, list((layer2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training input.\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31284349],\n",
       "       [0.6213127 ],\n",
       "       [0.62323891],\n",
       "       [0.46427804]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2 # Our output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[int(prediction > 0.5) for prediction in layer2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try adding another layer\n",
    "====\n",
    "\n",
    "Use the same process:\n",
    "    \n",
    "  1. Initialize\n",
    "  2. Forward Propagate\n",
    "  3. Back Propagate \n",
    "  4. Update (aka step)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def sigmoid(x): # Returns values that sums to one.\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(sx):\n",
    "    # See https://math.stackexchange.com/a/1225116\n",
    "    return sx * (1 - sx)\n",
    "\n",
    "# Cost functions.\n",
    "def cost(predicted, truth):\n",
    "    return truth - predicted\n",
    "\n",
    "xor_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "xor_output = np.array([[0,1,1,0]]).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = X.shape\n",
    "# Lets set the dimensions for the intermediate layer.\n",
    "layer0to1_hidden_dim = 5\n",
    "layer1to2_hidden_dim = 5\n",
    "\n",
    "# Initialize weights between the input layers 0 ->  layer 1\n",
    "W1 = np.random.random((input_dim, layer0to1_hidden_dim))\n",
    "\n",
    "# Initialize weights between the layer 1 -> layer 2\n",
    "W2 = np.random.random((layer0to1_hidden_dim, layer1to2_hidden_dim))\n",
    "\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(Y.T)\n",
    "# Initialize weights between the layer 2 -> layer 3\n",
    "W3 = np.random.random((layer1to2_hidden_dim, output_dim))\n",
    "\n",
    "# Initialize weigh\n",
    "num_epochs = 10000\n",
    "learning_rate = 1.0\n",
    "\n",
    "for epoch_n in range(num_epochs):\n",
    "    layer0 = X\n",
    "    # Forward propagation.\n",
    "    \n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(layer0, W1))\n",
    "    layer2 = sigmoid(np.dot(layer1, W2))\n",
    "    layer3 = sigmoid(np.dot(layer2, W3))\n",
    "\n",
    "    # Back propagation (Y -> layer2)\n",
    "    # How much did we miss in the predictions?\n",
    "    layer3_error = cost(layer3, Y)\n",
    "    # In what direction is the target value?\n",
    "    # Were we really close? If so, don't change too much.\n",
    "    layer3_delta = layer3_error * sigmoid_derivative(layer3)\n",
    "\n",
    "    # Back propagation (layer2 -> layer1)\n",
    "    # How much did each layer1 value contribute to the layer3 error (according to the weights)?\n",
    "    layer2_error = np.dot(layer3_delta, W3.T)\n",
    "    layer2_delta = layer3_error * sigmoid_derivative(layer2)\n",
    "    \n",
    "    # Back propagation (layer2 -> layer1)\n",
    "    # How much did each layer1 value contribute to the layer2 error (according to the weights)?\n",
    "    layer1_error = np.dot(layer2_delta, W2.T)\n",
    "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
    "    \n",
    "    # update weights\n",
    "    W3 +=  learning_rate * np.dot(layer2.T, layer3_delta)\n",
    "    W2 +=  learning_rate * np.dot(layer1.T, layer2_delta)\n",
    "    W1 +=  learning_rate * np.dot(layer0.T, layer1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50039537],\n",
       "       [0.50000003],\n",
       "       [0.9929507 ],\n",
       "       [0.50001378]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[int(prediction > 0.5) for prediction in layer3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, lets do it with PyTorch \n",
    "\n",
    "First lets try a single perceptron and see that we can't train a model that can represent XOR. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import FloatTensor\n",
    "from torch import optim\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(15, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # Original XOR X input in numpy array data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y # Original XOR Y output in numpy array data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "device = 'gpu' if torch.cuda.is_available()  else 'cpu'\n",
    "# Converting the X to PyTorch-able data structure.\n",
    "X_pt = torch.tensor(X).float()\n",
    "X_pt = X_pt.to(device)\n",
    "# Converting the Y to PyTorch-able data structure.\n",
    "Y_pt = torch.tensor(Y, requires_grad=False).float()\n",
    "Y_pt = Y_pt.to(device)\n",
    "print(X_pt)\n",
    "print(Y_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs Dim: 2\n",
      "Output Dim: 1\n"
     ]
    }
   ],
   "source": [
    "# Use tensor.shape to get the shape of the matrix/tensor.\n",
    "num_data, input_dim = X_pt.shape\n",
    "print('Inputs Dim:', input_dim)\n",
    "\n",
    "num_data, output_dim = Y_pt.shape\n",
    "print('Output Dim:', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Sequential to define a simple feed-forward network.\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim), # Use nn.Linear to get our simple perceptron\n",
    "            nn.Sigmoid()                      # Use nn.Sigmoid to get our sigmoid non-linearity\n",
    "        )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember we define as: cost = truth - predicted\n",
    "# If we take the absolute of cost, i.e.: cost = |truth - predicted|\n",
    "# we get the L1 loss function. \n",
    "criterion = nn.L1Loss() \n",
    "learning_rate = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The simple weights/parameters update processes we did before\n",
    "# is call the gradient descent. SGD is the sochastic variant of\n",
    "# gradient descent. \n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Note**: Personally, I strongely encourage you to go through the [University of Washington course of machine learning regression](https://www.coursera.org/learn/ml-regression) to better understand the fundamentals of (i) ***gradient***, (ii) ***loss*** and (iii) ***optimizer***. But given that you know how to code it, the process of more complex variants of gradient/loss computation and optimizer's step is easy to grasp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a PyTorch model\n",
    "\n",
    "To train a model using PyTorch, we simply iterate through the no. of epochs and imperatively state the computations we want to perform. \n",
    "\n",
    "## Remember the steps?\n",
    "\n",
    " 1. Initialize \n",
    " 2. Forward Propagation\n",
    " 3. Backward Propagation\n",
    " 4. Update Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 10000/10000 [00:02<00:00, 4373.51it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Initialization. \n",
    "# Note: When using PyTorch a lot of the manual weights\n",
    "#       initialization is done automatically when we define\n",
    "#       the model (aka architecture)\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim), \n",
    "            nn.Sigmoid())\n",
    "criterion = nn.MSELoss() \n",
    "learning_rate = 1.0\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 10000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in tqdm(range(num_epochs)):\n",
    "    # Reset the gradient after every epoch. \n",
    "    optimizer.zero_grad() \n",
    "    # Step 2: Foward Propagation\n",
    "    predictions = model(X_pt)\n",
    "    \n",
    "    # Step 3: Back Propagation \n",
    "    # Calculate the cost between the predictions and the truth.\n",
    "    loss_this_epoch = criterion(predictions, Y_pt)\n",
    "    # Note: The neat thing about PyTorch is it does the \n",
    "    #       auto-gradient computation, no more manually defining\n",
    "    #       derivative of functions and manually propagating\n",
    "    #       the errors layer by layer.\n",
    "    loss_this_epoch.backward()\n",
    "    \n",
    "    # Step 4: Optimizer take a step. \n",
    "    # Note: Previously, we have to manually update the \n",
    "    #       weights of each layer individually according to the\n",
    "    #       learning rate and the layer delta. \n",
    "    #       PyTorch does that automatically =)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Log the loss value as we proceed through the epochs.\n",
    "    losses.append(loss_this_epoch.data.item())\n",
    "    \n",
    "# Visualize the losses\n",
    "plt.plot(losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\t [0, 0]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n",
      "Input:\t [0, 1]\n",
      "Pred:\t 0\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 0]\n",
      "Pred:\t 0\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 1]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "for _x, _y in zip(X_pt, Y_pt):\n",
    "    prediction = model(_x)\n",
    "    print('Input:\\t', list(map(int, _x)))\n",
    "    print('Pred:\\t', int(prediction))\n",
    "    print('Ouput:\\t', int(_y))\n",
    "    print('######')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try again with 2 layers using PyTorch\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 5000/5000 [00:02<00:00, 1698.25it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.75 s, sys: 163 ms, total: 2.91 s\n",
      "Wall time: 3.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hidden_dim = 5\n",
    "num_data, input_dim = X_pt.shape\n",
    "num_data, output_dim = Y_pt.shape\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
    "                      nn.Sigmoid(), \n",
    "                      nn.Linear(hidden_dim, output_dim),\n",
    "                      nn.Sigmoid())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.3\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 5000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for _ in tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_pt)\n",
    "    loss_this_epoch = criterion(predictions, Y_pt)\n",
    "    loss_this_epoch.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss_this_epoch.data.item())\n",
    "    ##print([float(_pred) for _pred in predictions], list(map(int, Y_pt)), loss_this_epoch.data[0])\n",
    "    \n",
    "# Visualize the losses\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\t [0, 0]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n",
      "Input:\t [0, 1]\n",
      "Pred:\t 1\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 0]\n",
      "Pred:\t 1\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 1]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "for _x, _y in zip(X_pt, Y_pt):\n",
    "    prediction = model(_x)\n",
    "    print('Input:\\t', list(map(int, _x)))\n",
    "    print('Pred:\\t', int(prediction > 0.5))\n",
    "    print('Ouput:\\t', int(_y))\n",
    "    print('######')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST: The \"Hello World\" of Neural Nets\n",
    "====\n",
    "\n",
    "Like any deep learning class, we ***must*** do the MNIST. \n",
    "\n",
    "The MNIST dataset is \n",
    "\n",
    " - is made up of handwritten digits \n",
    " - 60,000 examples training set\n",
    " - 10,000 examples test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.2.2.post3)\r\n",
      "Requirement already satisfied: six in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torchvision) (1.13.0)\r\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from torchvision) (1.3.0)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from torchvision) (5.2.0)\r\n",
      "Requirement already satisfied: numpy in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torchvision) (1.18.1)\r\n"
     ]
    }
   ],
   "source": [
    "# We're going to install tensorflow here because their dataset access is simpler =)\n",
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST('../data', train=True, download=True, \n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "mnist_test = datasets.MNIST('../data', train=False, download=True, \n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Candies\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(mnist_x_vector, mnist_y_vector):\n",
    "    pixels = mnist_x_vector.reshape((28, 28))\n",
    "    label = np.where(mnist_y_vector == 1)[0]\n",
    "    plt.title('Label is {}'.format(label))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fifth image and label.\n",
    "show_image(mnist_train.data[5], mnist_train.targets[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets apply what we learn about multi-layered perceptron with PyTorch and apply it to the MNIST data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mnist = mnist_train.data.float()\n",
    "Y_mnist = mnist_train.targets.float()\n",
    "\n",
    "X_mnist_test = mnist_test.data.float()\n",
    "Y_mnist_test = mnist_test.targets.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images: 60000\n",
      "Inputs Dim: [28, 28]\n",
      "Output Dim: []\n"
     ]
    }
   ],
   "source": [
    "# Use FloatTensor.shape to get the shape of the matrix/tensor.\n",
    "num_data, *input_dim = X_mnist.shape\n",
    "print('No. of images:', num_data)\n",
    "print('Inputs Dim:', input_dim)\n",
    "\n",
    "num_data, *output_dim = Y_mnist.shape\n",
    "num_test_data, *output_dim = Y_mnist_test.shape\n",
    "print('Output Dim:', output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the dimensions of the images.\n",
    "X_mnist = mnist_train.data.float().view(num_data, -1)\n",
    "Y_mnist = mnist_train.targets.float().unsqueeze(1)\n",
    "\n",
    "X_mnist_test = mnist_test.data.float().view(num_test_data, -1)\n",
    "Y_mnist_test = mnist_test.targets.float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images: 60000\n",
      "Inputs Dim: [784]\n",
      "Output Dim: [1]\n"
     ]
    }
   ],
   "source": [
    "# Use FloatTensor.shape to get the shape of the matrix/tensor.\n",
    "num_data, *input_dim = X_mnist.shape\n",
    "print('No. of images:', num_data)\n",
    "print('Inputs Dim:', input_dim)\n",
    "\n",
    "num_data, *output_dim = Y_mnist.shape\n",
    "num_test_data, *output_dim = Y_mnist_test.shape\n",
    "print('Output Dim:', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAD7CAYAAACYLnSTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXJElEQVR4nO3de4xcZ3nH8e/M7H12fZs5vuysnZQkPCVu0oQoEU1IiYQJQipFUSFWI1QiaEMRUAe8dQOFJm3VUgENVVHbIERoJFpC1TRRwSVQEqJCaSFQhbTGeUjT0NTeNRmv7dh7sfc2/WNmvF5nL2fWO3vmnPP7SJZ2zszsefIq+eX4Oe9530ylUkFEROItG3UBIiJy4RTmIiIJoDAXEUkAhbmISAIozEVEEqAtgnN2AtcCw8BMBOcXEYmjHLANeBI4c/6bUYT5tcC3IjiviEgS3Ah8+/yDUYT5MMDx42PMzjY+x71Q6GVkZHTVi4orjcd8Go85Gov54j4e2WyGjRvzUMvQ80UR5jMAs7OVFYV5/bsyR+Mxn8ZjjsZivoSMx4Ltad0AFRFJAIW5iEgCKMxFRBJAYS4ikgAKcxGRBFCYi4gkQKzC/OnnRnj/J7/J1PRs1KWIiLSUWIX56clpfjJ8kiPHxqMuRUSkpcQqzEvFPACHy/F9iktEpBliFeZbNvXQlstw+OhY1KWIiLSUWIV5Wy5Lf9DL4bLCXETkXLEKc4CLtq7j8FG1WUREzhXDMO+jfOI0Zya1FLqISF3swnzH1nUADI2o1SIiUhe7ML9oWx8AhzSjRUTkrNiF+ZZNedrbsroJKiJyjlCbU5jZ3cCttZf73X2fmf0C8CmgD3gaeIe7TzanzDm5bIb+Qp4hTU8UETlr2StzM9sF3AxcDVwFXGNm7wD+AbjD3XfWPvquplV5nlKQ11xzEZFzhGmzDAN73X3S3aeAg8DFwL+5+9O1z7wfeLg5Jb5cKchz/NQZxk5PrdUpRURa2rJtFnc/UP/ZzC4DdgOfBEbN7GHgEuBbwN5GTlwo9DZW6TkuvySAbz7H2FSFi7f3rfj3JEUQaAzOpfGYo7GYL8njEXpDZzPbCewHBoEB4I3Aa4AXgM8BdwH3hP19IyOjK9pcNQj66G2v/oXiwH+X2dzX0fDvSJIg6KNcPhV1GS1D4zFHYzFf3Mcjm80seREcajaLmd0APAbc5e4PAEeAf3f35919Bvg74LpVqDeUTes66erIMaQZLSIiQLgboNuBR4Db3P3B2uGvU70Rur32+peAHzSnxJfLZDK1m6Caay4iAuHaLINAF3CvmdWP3Qe8G/iymXUBT9U+t2ZKxV7+48dlKpUKmUxmLU8tItJywtwA3QPsWeTt/atbTnilYp5/+eEQJ8enWJ9Pd99cRCR2T4DWlQJtVCEiUhfjMK/e1dXDQyIiMQ7zdT3t9Ha3a40WERFiHOaZTIYBzWgREQFiHOYA/cU8h8tjVCqNP3wkIpIksQ7zUtDL6ckZjp08E3UpIiKRineYF2szWnQTVERSLt5hXp+eqL65iKRcrMM839XOxr5OzWgRkdSLdZjD3E1QEZE0i32Yl4p5hkbGVrScrohIUsQ/zIM8U9OzlF+aiLoUEZHIxD7MB+qP9avVIiIpFvsw7y9owS0RkdiHeWdHjuL6Ls01F5FUi32YQ7XVojaLiKRZIsK8FOQ5cmyc6ZnZqEsREYlEMsK8mGdmtsJPj41HXYqISCSSEebaqEJEUi4RYb51Uw/ZTIZD6puLSEolIszb27Js2dSt6YkiklqJCHOoPdavNouIpFRywjzo5cXjE0xOzURdiojImmsL8yEzuxu4tfZyv7vvM7P7gRuB+uXw77v7w02oMZRSMU8FGB4Z56KtfVGVISISiWXD3Mx2ATcDVwMV4FEzuwW4FvhFdx9ubonh1DeqOFQeVZiLSOqEuTIfBva6+ySAmR0EdtT+fNbMdgAPU70yj+ypnc0bu2nLZdQ3F5FUWjbM3f1A/WczuwzYDbwWuAl4NzAKfAV4F/DZplQZQi6bZVshr7nmIpJKoXrmAGa2E9gPDLq7A7ec896ngV+jgTAvFHobKHO+IFi4jXLJwAYOPD+y6PtJlbZ/3uVoPOZoLOZL8niEvQF6A/AQcKe7P2hmVwCvdPeHah/JAFONnHhkZHRFuwMFQR/l8qkF3yv0dVA+PsELh47T3Rn6/1OxttR4pJHGY47GYr64j0c2m1nyInjZqYlmth14BLjN3R+sHc4Af2ZmG82sHbiDat88UqWiHusXkXQKc/k6CHQB95pZ/dh9wMeAfwXagYfc/YtNqbAB9RktQ0fHuLS0PuJqRETWTpgboHuAPYu8/ZerW86FKazvorM9xyE91i8iKZOYJ0ABspkM/cW8NqoQkdRJVJhD9UlQ9cxFJG2SF+ZBnpNjk5wan4y6FBGRNZPIMAf0JKiIpErywrw2PVEbVYhImiQuzDf0dpDvalPfXERSJXFhnjk7o0XTE0UkPRIX5lDdqOJweYxKpfHlAkRE4iiZYV7MM35mmhOjmtEiIumQyDAfqM1oOXxUrRYRSYdEhnl/sRbmmtEiIimRyDDv6+lgXb5DYS4iqZHIMIf6Y/1qs4hIOiQ3zIM8Q0fHmdWMFhFJgcSG+UDQy5mpGUZeOh11KSIiTZfYMC/pJqiIpEhiw/zsjBb1zUUkBRIb5t2dbRTWderKXERSIbFhDrXH+rXgloikQLLDvJhneGSMmdnZqEsREWmqZId5kGd6psKLxyeiLkVEpKmSHea1jSrUNxeRpEt0mG8r9JABDmltcxFJuLYwHzKzu4Fbay/3u/u+c957L/A2d79p9cu7MB3tOTZv7NZ+oCKSeMtemZvZLuBm4GrgKuAaM7ul9t7lwIeaWuEF0owWEUmDMG2WYWCvu0+6+xRwENhhZp3AZ4CPNrPAC1Uq5vnpsQmmpmeiLkVEpGmWbbO4+4H6z2Z2GbAbuB74GHA/8HzTqlsFpSDPbKXC8Mg4O7b0RV2OiEhThOqZA5jZTmA/MAhcDOxw9w+a2U0rOXGh0LuSrwEQBOFD+edmKsABTp2Zaeh7cZLUf66V0njM0VjMl+TxCHsD9AbgIeBOd3/QzO4HdprZU0AvsNXMvuTuu8OeeGRklNnZxpenDYI+yuVToT/fQYVcNsMzz4+wc8eGhs/X6hodj6TTeMzRWMwX9/HIZjNLXgQvG+Zmth14BNjt7o8DuPs7z3n/JuCeRoJ8LbXlsmwt9GiuuYgkWpgr80GgC7jXzOrH7nP3+5pW1SorFfP8z9DJqMsQEWmaMDdA9wB7lnj/CeCm1Stp9ZWKeb538EVOT07T1RH6NoGISGwk+gnQulJQ7TMNHR2PuBIRkeZISZhrowoRSbZUhHmwvpuOtqxugopIYqUizLPZDNsKeT3WLyKJlYowh2qr5bBWTxSRhEpVmJ8YnWTs9FTUpYiIrLr0hLk2qhCRBEtNmA+cndGiMBeR5ElNmG/s66S7M6e+uYgkUmrCPJPJ0F/Mq80iIomUmjCHat/88NExKpXGV2sUEWll6QrzIM/oxBQnxzWjRUSSJVVhPlCs3QRV31xEEiZVYd4faHqiiCRTqsJ8XU87vd3tWnBLRBInVWGeyWQYCLRGi4gkT6rCHGozWsqa0SIiyZK+MA/ynJ6c4djJM1GXIiKyalIX5v1FbVQhIsmTujA/u+uQZrSISIKkLszzXe1s7OvUTVARSZTUhTlASWu0iEjCpDPMgzxDI2PMzmpGi4gkQyrDvL+YZ2p6lvKJiahLERFZFW1hPmRmdwO31l7ud/d9ZvYe4H1ABtgP7HP3WFzqDtQe6z9UHmPLpp6IqxERuXDLXpmb2S7gZuBq4CrgGjP7APBB4DrgCuB64A1NrHNV9ReqM1qGND1RRBIiTJtlGNjr7pPuPgUcBGaBy919DNgArAdONK/M1dXZkSPY0KUZLSKSGMu2Wdz9QP1nM7sM2A1c7+5TZvYbwCeB7wFPNXLiQqG3wVLnBEHfir9b94rSBoZHxlbld0UtCf8Mq0njMUdjMV+SxyNUzxzAzHZS7Y0PuvuzAO7+WTP7PPB54B7gw2F/38jI6IpmkwRBH+XyqYa/d77iuk6+f/CnDB95ibZcfO8Dr9Z4JIXGY47GYr64j0c2m1nyIjhUipnZDcBjwF3u/oCZba8dw92ngQeBK1eh3jVTKuaZma1w5Nh41KWIiFywZa/MzWw78Aiw290frx1eD/yNmV0FvAS8Ffh206psglJtRsvQ0bGzs1tEROIqTJtlEOgC7jWz+rH7gI8B3wGmgW8Bf9qMAptl66YespkMh8pjXPeqqKsREbkwYW6A7gH2LPL2Z1a3nLXT3pZly6Zu7QcqIokQ3zt/q6BU1K5DIpIM6Q7zoJfy8QnOTM1EXYqIyAVJd5gX81SAIyOa0SIi8ZbuMK9tVHFIfXMRiblUh/nmjd205bLqm4tI7KU6zHPZLNsKPdqoQkRiL9VhDtVWizZ3FpG4U5gX8xw7eYaJM9NRlyIismIK89qj/Oqbi0icKcyL1RktehJUROIs9WFeWN9FZ3tON0FFJNZSH+bZTIZ+PdYvIjGX+jCH+owWhbmIxJfCHBgo5jk5NsnJ8cmoSxERWRGFOdBfe6x/SH1zEYkphTlQKmp6oojEm8Ic2NDbQb6rTdMTRSS2FOZAJpPRRhUiEmsK85pS0Mvh8hiVSiXqUkREGqYwr+kv5hk/M82JUc1oEZH4UZjXDAR6rF9E4kthXtNfX6NFfXMRiSGFeU1fTwfr8x1ao0VEYqktzIfM7G7g1trL/e6+z8zuAH4LqADfB97t7rFuOGujChGJq2WvzM1sF3AzcDVwFXCNmf0O8NvA9cCVtd/z3ibWuSbqC27NakaLiMRMmDbLMLDX3SfdfQo4CHQB73H3k+5eAf4T2NHEOtfEQNDL5NQsR186HXUpIiINWbbN4u4H6j+b2WXAbuB6d3+2diwA3gfc3qQa10x9o4qh8hibN3RHXI2ISHiheuYAZrYT2A8MnhPkJeCrwOfc/YlGTlwo9Dby8XmCoG/F311Kvq8LgBMTU007RzPEqda1oPGYo7GYL8njEfYG6A3AQ8Cd7v5g7djPAo8Cn3b3P230xCMjo8zONt6bDoI+yuVTDX8vrMK6Ln78k2NNPcdqavZ4xI3GY47GYr64j0c2m1nyInjZMDez7cAjwG53f7x2rA/4OvBhd//CKtXaEkpBnkOanigiMRPmynyQ6g3Pe82sfuxLwBZg0MwGa8f+0d1/b/VLXFulYp4f/eQYM7Oz5LKahi8i8RDmBugeYM8Cb31s9cuJXinIMz1T4cXjE2wr5KMuR0QkFF16nufsRhVqtYhIjCjMz7Ot0EMmA4e04JaIxIjC/Dwd7Tk2b+jWglsiEisK8wXUN6oQEYkLhfkCSsU8Lx6fYGp6JupSRERCUZgvoBTkma1UGB4Zj7oUEZFQFOYLKAW1GS3qm4tITCjMF7BlYze5bEZ9cxGJDYX5AtpyWbYWerQfqIjEhsJ8EaXaRhUiInGgMF9EKejl6EunOT05HXUpIiLLUpgvYqC+UcVRzWgRkdanMF9Ef1ANc/XNRSQOFOaLCNZ309GWVd9cRGJBYb6IbDbDNt0EFZGYUJgvYaCYV5tFRGJBYb6E/iDPidFJRiemoi5FRGRJCvMl1DeqGFKrRURanMJ8CQOa0SIiMaEwX8LGvk66O3O6CSoiLU9hvoRMJkOpqI0qRKT1KcyX0V+bnlipVKIuRURkUQrzZZSCPKMTU5wcm4y6FBGRRbWF+ZCZ3Q3cWnu539331Y63A48Cf+juTzSlwojV12g5dHSM9b2dEVcjIrKwZcPczHYBNwNXAxXgUTO7BfgRcD/w6qZWGLH6rkND5TF2Xrwp4mpERBYWps0yDOx190l3nwIOAjuAdwGfAL7bxPoity7fQV9PO4ePanqiiLSuZa/M3f1A/WczuwzYDVzv7s/Wjt3ZvPJaQ6mY14wWEWlpoXrmAGa2E9gPDNaD/EIUCr0r/m4Q9F3o6Rty6faNPPb9FygWe8lkMmt67jDWejxancZjjsZiviSPR9gboDcADwF3uvuDq3HikZFRZmcbn+4XBH2Uy6dWo4TQNvV2MHFmhmeeK1Nc372m515OFOPRyjQeczQW88V9PLLZzJIXwcv2zM1sO/AIcNtqBXnclIL6rkNqtYhIawpzZT4IdAH3mln92H3ufl/TqmoxpWJ9jZYxrrykGHE1IiIvF+YG6B5gzxLv37SaBbWinq52NvZ1ckg3QUWkRekJ0JBKxbymJ4pIy1KYh1QK8gyPjK/opq2ISLMpzEMqFXuZmp6lfGIi6lJERF5GYR5SfUaL+uYi0ooU5iH1F2ozWtQ3F5EWpDAPqbMjR7ChS4/1i0hLUpg3oFTs1YNDItKSFOYNKAV5jhwbZ3pmNupSRETmUZg3oBTkmZmtcOTYeNSliIjMozBvQKlYXeRGfXMRaTUK8wZs3dRDNpPRjBYRaTkK8wa0t2XZsqlbV+Yi0nIU5g0qBb0c1owWEWkxCvMGDRTzlI9PcGZqJupSRETOUpg3qL+YpwIMj+jqXERah8K8QfU1WtQ3F5FWojBv0OaN3bTlsuqbi0hLCbWhs8zJZbP0F3rwF47z5DMvRl0O64ZOcvLk6ajLaBkajzkai/laYTzac1muuGQTuezqX0crzFfgFf3reOKpIf7qkf+KuhQRiZm9u69i589sWvXfqzBfgdve8Epef81A1GUAsHFTnuPH1PKp03jM0VjM1wrj0d6WZfPGnqb8boX5CrTlspSC3qjLACAI+ujJZaIuo2VoPOZoLOZL+njoBqiISAIozEVEEkBhLiKSAKF65mZ2N3Br7eV+d99nZruAe4Fu4Evu/pEm1SgiIstY9sq8Fto3A1cDVwHXmNmvAvcDbwFeBVxrZm9qZqEiIrK4MG2WYWCvu0+6+xRwEHgl8Ky7P+/u08AXgLc1sU4REVnCsm0Wdz9Q/9nMLgN2A39ONeTrhoGwE69zAIXCyqf2BUHfir+bRBqP+TQeczQW8yVkPHILHQx9A9TMdgL/DAwCzy3wkbC7HG8Le04REXmZBTM07A3QG4CHgDvd/UEzex2w9bxfPhSykCeBG6lezWtRcBGRcHJUs/bJhd5cNszNbDvwCLDb3R+vHf5u9S27FHgeuI3qDdEwzgDfDvlZERGZs1BXBAh3ZT4IdAH3mln92H3A7VSv1ruAfwL+/oJKFBGRFctUKpWoaxARkQukJ0BFRBJAYS4ikgAKcxGRBFCYi4gkgMJcRCQBYrXTkJndBnwE6AA+5e5/EXFJkVloJcso62kVZvYJIHD326OuJUpm9mbgHiAPfM3d90RbUXTM7O3Ah2ovv+rug1HW0yyxuTI3sxLwR8BrgZ8H7jCzy6OtKhqLrGR5S7RVRc/MXk/1+YdUM7NXUH0W5C3AFcCr07qqqZn1UF1L6nVUc+PG2n8/iRObMAd2AY+7+zF3H6P6kNJbI64pKgutZLkj4poiZWabqP7P/o+jrqUF3EJ1j4FDtX8/dlN9ajuNclRzLg+01/5MRFpRk8SpzdLPy1dqvC6iWiK1yEqW10dXUUv4DPC7wPaoC2kBlwKTZvY1qmsofRn4aLQlRcPdT5nZR4FnqIb4E8B3Ii2qSeJ0Zb7QttphV2pMpHNXsnT3Z6OuJypm9uvA/7n7Y1HX0iLaqP5N9u3Aa6he9Lwj0ooiYmZXAu8ELqK6SNUM1SVKEidOYX6Yla/UmDi1lSwfA+5y9weiridiu4Gbzewp4A+AXzazT0VcU5SOAN9w97K7T1BdKC+Vf4sF3gg85u4vuvsZ4K+BmyKtqEni1Gb5BnCPmQXAGPArwB3RlhSNRVayTC13f0P9ZzO7HbjJ3T8QXUWR+wrwgJltAE4Bb6L670sa/RD4uJnlgXHgzSyyhGzcxebK3N0PU+2JfhN4Cvhbd/9etFVF5tyVLJ+q/fnNqIuS1uDu3wU+TnWp6R8B/wt8PtKiIuLuXwe+CPwAeJrqDdA/ibSoJtGqiSIiCRCbK3MREVmcwlxEJAEU5iIiCaAwFxFJAIW5iEgCKMxFRBJAYS4ikgAKcxGRBPh/dKys5TO4qrEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 10/10 [00:07<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 500\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 1),\n",
    "                      nn.Sigmoid())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1.0\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "losses = []\n",
    "plt.ion()\n",
    "\n",
    "for _e in tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_mnist)\n",
    "    loss_this_epoch = criterion(predictions, Y_mnist)\n",
    "    loss_this_epoch.backward()\n",
    "    optimizer.step()\n",
    "    ##print([float(_pred) for _pred in predictions], list(map(int, Y_pt)), loss_this_epoch.data[0])\n",
    "    losses.append(loss_this_epoch.data.item())\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(losses)\n",
    "    plt.pause(0.05)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(X_mnist_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.array([np.argmax(_p) for _p in predictions.data.numpy()])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = np.array([np.argmax(_p) for _p in Y_mnist_test.data.numpy()])\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred == truth).sum() / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
